{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"openai.api_key\")\n",
    "\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Initialize the model and processor\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Setup device for PyTorch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Image folder path\n",
    "image_folder = r\"E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\"\n",
    "\n",
    "# File to save the output\n",
    "output_file_path = r\"E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\classification_results.txt\"\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file_path, 'w') as file:\n",
    "    # Loop through each image in the folder\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        \n",
    "        if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check if it's an image file\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Process the image\n",
    "            inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "            pixel_values = inputs.pixel_values\n",
    "\n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                outputs = model(pixel_values)\n",
    "                logits = outputs.logits\n",
    "\n",
    "            prediction = logits.argmax(-1)\n",
    "            classification = model.config.id2label[prediction.item()]\n",
    "\n",
    "            # Write the results to the file\n",
    "            file.write(f\"{image_file} : {classification}\\n\")\n",
    "\n",
    "print(\"Classification completed and results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_1020.jpg : traffic light, traffic signal, stoplight\n",
      "frame_1080.jpg : gown\n",
      "frame_1140.jpg : ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\n",
      "frame_120.jpg : bearskin, busby, shako\n",
      "frame_1200.jpg : lakeside, lakeshore\n",
      "frame_1260.jpg : lakeside, lakeshore\n",
      "frame_1320.jpg : pole\n",
      "frame_1380.jpg : pole\n",
      "frame_1440.jpg : park bench\n",
      "frame_1500.jpg : crane\n",
      "frame_1560.jpg : planetarium\n",
      "frame_1620.jpg : triumphal arch\n",
      "frame_1680.jpg : swing\n",
      "frame_1740.jpg : lakeside, lakeshore\n",
      "frame_180.jpg : academic gown, academic robe, judge's robe\n",
      "frame_1800.jpg : lakeside, lakeshore\n",
      "frame_1860.jpg : lakeside, lakeshore\n",
      "frame_1920.jpg : lakeside, lakeshore\n",
      "frame_1980.jpg : jersey, T-shirt, tee shirt\n",
      "frame_2040.jpg : pole\n",
      "frame_2100.jpg : crutch\n",
      "frame_2160.jpg : torch\n",
      "frame_2220.jpg : trench coat\n",
      "frame_2280.jpg : miniskirt, mini\n",
      "frame_2340.jpg : monastery\n",
      "frame_240.jpg : sarong\n",
      "frame_2400.jpg : fur coat\n",
      "frame_2460.jpg : bearskin, busby, shako\n",
      "frame_2520.jpg : mailbag, postbag\n",
      "frame_2580.jpg : street sign\n",
      "frame_2640.jpg : cinema, movie theater, movie theatre, movie house, picture palace\n",
      "frame_2700.jpg : tobacco shop, tobacconist shop, tobacconist\n",
      "frame_2760.jpg : unicycle, monocycle\n",
      "frame_2820.jpg : cinema, movie theater, movie theatre, movie house, picture palace\n",
      "frame_2880.jpg : street sign\n",
      "frame_2940.jpg : miniskirt, mini\n",
      "frame_300.jpg : miniskirt, mini\n",
      "frame_3000.jpg : pole\n",
      "frame_3060.jpg : street sign\n",
      "frame_3120.jpg : crutch\n",
      "frame_3180.jpg : street sign\n",
      "frame_3240.jpg : bell cote, bell cot\n",
      "frame_3300.jpg : neck brace\n",
      "frame_3360.jpg : cab, hack, taxi, taxicab\n",
      "frame_3420.jpg : bell cote, bell cot\n",
      "frame_3480.jpg : unicycle, monocycle\n",
      "frame_3540.jpg : unicycle, monocycle\n",
      "frame_360.jpg : miniskirt, mini\n",
      "frame_3600.jpg : cinema, movie theater, movie theatre, movie house, picture palace\n",
      "frame_3660.jpg : crutch\n",
      "frame_3720.jpg : jinrikisha, ricksha, rickshaw\n",
      "frame_3780.jpg : palace\n",
      "frame_3840.jpg : street sign\n",
      "frame_3900.jpg : pole\n",
      "frame_3960.jpg : streetcar, tram, tramcar, trolley, trolley car\n",
      "frame_4020.jpg : bicycle-built-for-two, tandem bicycle, tandem\n",
      "frame_4080.jpg : street sign\n",
      "frame_4140.jpg : traffic light, traffic signal, stoplight\n",
      "frame_420.jpg : crutch\n",
      "frame_4200.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4260.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4320.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4380.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4440.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4500.jpg : street sign\n",
      "frame_4560.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4620.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4680.jpg : traffic light, traffic signal, stoplight\n",
      "frame_4740.jpg : street sign\n",
      "frame_480.jpg : miniskirt, mini\n",
      "frame_4800.jpg : crutch\n",
      "frame_4860.jpg : crutch\n",
      "frame_4920.jpg : crutch\n",
      "frame_4980.jpg : crutch\n",
      "frame_540.jpg : miniskirt, mini\n",
      "frame_60.jpg : miniskirt, mini\n",
      "frame_600.jpg : tobacco shop, tobacconist shop, tobacconist\n",
      "frame_660.jpg : tobacco shop, tobacconist shop, tobacconist\n",
      "frame_720.jpg : tobacco shop, tobacconist shop, tobacconist\n",
      "frame_780.jpg : miniskirt, mini\n",
      "frame_840.jpg : jean, blue jean, denim\n",
      "frame_900.jpg : miniskirt, mini\n",
      "frame_960.jpg : pole\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "file_path = r\"E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\classification_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, \"r\") as file:\n",
    "    file_contents = file.read()\n",
    "\n",
    "# Now you can print the contents, or use them elsewhere in your program\n",
    "print(file_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560, 1620, 2340, 3780, 3960\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"Task Description: You are assigned the task of meticulously choosing 5 image frames from the given list: {file_contents}. Your selections should be optimally conducive for identifying the geographical locations depicted in the images. Adhere to the following guidelines for your selection:\n",
    "    Clear Geographical Indicators: Prioritize frames that display clear and identifiable geographical features, such as landmarks, unique natural landscapes, or distinct architectural styles.\n",
    "    Diversity in Selection: Ensure a diverse range of images. Avoid selecting multiple frames that depict similar scenes or subjects. The goal is to have a variety of images that could potentially represent different aspects or areas of the location.\n",
    "    Incorporate Cultural Elements: Where applicable, include frames that show cultural or local elements — such as street signs, local businesses, or cultural landmarks — which might offer additional contextual clues.\n",
    "    Frame Number Identification: In your response, list only the frame numbers that correspond to your selections. The format should be concise, e.g., \"59\", \"1475\", indicating the frame numbers you've chosen.\n",
    "Remember, the effectiveness of the geolocation analysis largely depends on the diversity and clarity of the images you select. Your discerning eye for detail and context is crucial in this task.\"\"\"\n",
    "\n",
    "\n",
    "def select_best_images(system_prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to select the best frames. Your answers need to look like this: Frame XY ONLY respond with the relevant Frames. If there are less or just 5 Frames just pick all of them.\" },\n",
    "            {\"role\": \"user\", \"content\": system_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    # Extract only the frame numbers using a regular expression\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "best_images = select_best_images(system_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(best_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560, 1620, 2340, 3780, 3960\n",
      "[1560, 1620, 2340, 3780, 3960]\n",
      "Selected: E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\\frame_1560.jpg\n",
      "Selected: E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\\frame_1620.jpg\n",
      "Selected: E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\\frame_2340.jpg\n",
      "Selected: E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\\frame_3780.jpg\n",
      "Selected: E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\\frame_3960.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Paths to the folders\n",
    "image_folder_path = r\"E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\images\"\n",
    "destination_folder_path = r\"E:\\VS_Code\\ZHAW\\ML2\\Image_class_test\\relevant_images\"\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "os.makedirs(destination_folder_path, exist_ok=True)\n",
    "\n",
    "# List of frame numbers you want to select\n",
    "frame_numbers = best_images  # Assuming this is a list of integers\n",
    "print(frame_numbers)\n",
    "frame_numbers = [int(num.strip()) for num in best_images.split(',')]\n",
    "print(frame_numbers)\n",
    "\n",
    "# Regular expression to extract number from file name\n",
    "number_pattern = re.compile(r'frame_(\\d+)\\.')\n",
    "\n",
    "# Loop through the files in the image folder\n",
    "for file in os.listdir(image_folder_path):\n",
    "    # Extract the number from the file name\n",
    "    match = number_pattern.search(file)\n",
    "    if match:\n",
    "        file_number = int(match.group(1))\n",
    "        # Check if the file number is in frame_numbers\n",
    "        if file_number in frame_numbers:\n",
    "            file_path = os.path.join(image_folder_path, file)\n",
    "            shutil.copy(file_path, destination_folder_path)\n",
    "            print(f\"Selected: {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
